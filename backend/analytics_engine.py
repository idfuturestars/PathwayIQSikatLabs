"""
IDFS PathwayIQâ„¢ Analytics Engine - Phase 3
Complete analytics system with:
- Advanced Learning Analytics Dashboard
- Predictive Analytics for learning outcomes
- Comprehensive Reporting for educators
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timezone, timedelta
from enum import Enum
from pydantic import BaseModel, Field
import uuid
import numpy as np
import pandas as pd
from collections import defaultdict
import json
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class AnalyticsType(str, Enum):
    LEARNING_PROGRESS = "learning_progress"
    PERFORMANCE_TRENDS = "performance_trends"
    ENGAGEMENT_METRICS = "engagement_metrics"
    SKILL_MASTERY = "skill_mastery"
    PREDICTIVE_OUTCOMES = "predictive_outcomes"
    COMPARATIVE_ANALYSIS = "comparative_analysis"

class ReportType(str, Enum):
    INDIVIDUAL_STUDENT = "individual_student"
    CLASS_SUMMARY = "class_summary"
    SUBJECT_PERFORMANCE = "subject_performance"
    ENGAGEMENT_REPORT = "engagement_report"
    PREDICTIVE_REPORT = "predictive_report"
    INTERVENTION_REPORT = "intervention_report"

class PredictionModel(str, Enum):
    SUCCESS_PROBABILITY = "success_probability"
    COMPLETION_TIME = "completion_time"
    DROPOUT_RISK = "dropout_risk"
    PERFORMANCE_FORECAST = "performance_forecast"
    OPTIMAL_LEARNING_PATH = "optimal_learning_path"

class AnalyticsData(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str
    analytics_type: AnalyticsType
    data: Dict[str, Any]
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    metadata: Dict[str, Any] = {}

class Report(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    report_type: ReportType
    title: str
    description: str
    generated_for: str  # user_id or class_id
    data: Dict[str, Any]
    generated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    generated_by: str
    format: str = "json"  # json, pdf, csv
    is_scheduled: bool = False
    schedule_config: Dict[str, Any] = {}

class PredictionResult(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str
    model_type: PredictionModel
    prediction: Dict[str, Any]
    confidence: float
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    model_version: str = "1.0"
    features_used: List[str] = []

class AdvancedAnalyticsEngine:
    def __init__(self):
        self.prediction_models = {}
        self.analytics_cache = {}
        self.report_templates = self._initialize_report_templates()
        self.ml_models = self._initialize_ml_models()
        
    def _initialize_report_templates(self) -> Dict[str, Dict[str, Any]]:
        """Initialize report templates"""
        return {
            "individual_student": {
                "sections": [
                    "personal_overview",
                    "learning_progress",
                    "skill_assessment",
                    "engagement_metrics",
                    "recommendations",
                    "next_steps"
                ],
                "visualizations": [
                    "progress_chart",
                    "skill_radar",
                    "engagement_timeline",
                    "performance_trends"
                ]
            },
            "class_summary": {
                "sections": [
                    "class_overview",
                    "performance_distribution",
                    "engagement_analysis",
                    "skill_gaps",
                    "intervention_recommendations"
                ],
                "visualizations": [
                    "class_performance_histogram",
                    "skill_mastery_heatmap",
                    "engagement_dashboard",
                    "progress_comparison"
                ]
            },
            "subject_performance": {
                "sections": [
                    "subject_overview",
                    "topic_mastery",
                    "difficulty_analysis",
                    "time_allocation",
                    "improvement_areas"
                ],
                "visualizations": [
                    "topic_mastery_chart",
                    "difficulty_distribution",
                    "time_spent_analysis",
                    "improvement_trajectory"
                ]
            }
        }
    
    def _initialize_ml_models(self) -> Dict[str, Any]:
        """Initialize machine learning models"""
        return {
            "success_predictor": RandomForestRegressor(n_estimators=100, random_state=42),
            "completion_time_predictor": LinearRegression(),
            "dropout_risk_classifier": RandomForestRegressor(n_estimators=100, random_state=42),
            "performance_forecaster": LinearRegression(),
            "scaler": StandardScaler()
        }
    
    async def generate_learning_analytics(self, user_id: str, time_range: str = "30d") -> Dict[str, Any]:
        """Generate comprehensive learning analytics for a user"""
        try:
            # Get user activity data
            user_data = await self._get_user_activity_data(user_id, time_range)
            
            # Calculate core metrics
            core_metrics = await self._calculate_core_metrics(user_data)
            
            # Generate learning progress analysis
            progress_analysis = await self._analyze_learning_progress(user_data)
            
            # Calculate engagement metrics
            engagement_metrics = await self._calculate_engagement_metrics(user_data)
            
            # Skill mastery analysis
            skill_analysis = await self._analyze_skill_mastery(user_data)
            
            # Generate insights and recommendations
            insights = await self._generate_insights(user_data, core_metrics)
            
            return {
                "user_id": user_id,
                "time_range": time_range,
                "core_metrics": core_metrics,
                "learning_progress": progress_analysis,
                "engagement_metrics": engagement_metrics,
                "skill_analysis": skill_analysis,
                "insights": insights,
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error generating learning analytics: {e}")
            return {"error": str(e)}
    
    async def _get_user_activity_data(self, user_id: str, time_range: str) -> Dict[str, Any]:
        """Get user activity data from database"""
        # This would query the database for user activity
        # For now, return simulated data
        return {
            "sessions": [
                {
                    "date": "2024-01-15",
                    "duration": 45,
                    "questions_answered": 12,
                    "correct_answers": 10,
                    "subject": "mathematics"
                },
                {
                    "date": "2024-01-16",
                    "duration": 60,
                    "questions_answered": 15,
                    "correct_answers": 13,
                    "subject": "mathematics"
                }
            ],
            "assessments": [
                {
                    "date": "2024-01-15",
                    "subject": "mathematics",
                    "score": 85,
                    "time_taken": 30,
                    "difficulty": "intermediate"
                }
            ],
            "ai_interactions": [
                {
                    "date": "2024-01-15",
                    "interaction_type": "help_request",
                    "topic": "algebra",
                    "duration": 5
                }
            ]
        }
    
    async def _calculate_core_metrics(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate core learning metrics"""
        sessions = user_data.get("sessions", [])
        assessments = user_data.get("assessments", [])
        
        if not sessions:
            return {}
        
        # Calculate basic metrics
        total_sessions = len(sessions)
        total_time = sum(session["duration"] for session in sessions)
        total_questions = sum(session["questions_answered"] for session in sessions)
        total_correct = sum(session["correct_answers"] for session in sessions)
        
        accuracy = (total_correct / total_questions * 100) if total_questions > 0 else 0
        avg_session_time = total_time / total_sessions if total_sessions > 0 else 0
        
        # Calculate assessment metrics
        assessment_scores = [assessment["score"] for assessment in assessments]
        avg_assessment_score = sum(assessment_scores) / len(assessment_scores) if assessment_scores else 0
        
        return {
            "total_sessions": total_sessions,
            "total_study_time": total_time,
            "total_questions_answered": total_questions,
            "overall_accuracy": accuracy,
            "average_session_time": avg_session_time,
            "average_assessment_score": avg_assessment_score,
            "engagement_score": self._calculate_engagement_score(user_data),
            "learning_velocity": self._calculate_learning_velocity(sessions)
        }
    
    def _calculate_engagement_score(self, user_data: Dict[str, Any]) -> float:
        """Calculate user engagement score"""
        sessions = user_data.get("sessions", [])
        ai_interactions = user_data.get("ai_interactions", [])
        
        if not sessions:
            return 0.0
        
        # Factors that contribute to engagement
        session_frequency = len(sessions) / 30  # sessions per day
        avg_session_duration = sum(s["duration"] for s in sessions) / len(sessions)
        ai_interaction_rate = len(ai_interactions) / len(sessions) if sessions else 0
        
        # Normalize and combine factors
        engagement_score = (
            min(session_frequency * 20, 40) +  # Max 40 points for frequency
            min(avg_session_duration / 2, 30) +  # Max 30 points for duration
            min(ai_interaction_rate * 30, 30)  # Max 30 points for interaction
        )
        
        return min(engagement_score, 100)
    
    def _calculate_learning_velocity(self, sessions: List[Dict[str, Any]]) -> float:
        """Calculate learning velocity (improvement over time)"""
        if len(sessions) < 2:
            return 0.0
        
        # Calculate accuracy trend
        accuracies = []
        for session in sessions:
            if session["questions_answered"] > 0:
                accuracy = session["correct_answers"] / session["questions_answered"]
                accuracies.append(accuracy)
        
        if len(accuracies) < 2:
            return 0.0
        
        # Simple linear trend
        x = np.arange(len(accuracies))
        y = np.array(accuracies)
        slope = np.corrcoef(x, y)[0, 1] if len(x) > 1 else 0
        
        return slope * 100  # Convert to percentage
    
    async def _analyze_learning_progress(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze learning progress patterns"""
        sessions = user_data.get("sessions", [])
        
        if not sessions:
            return {}
        
        # Group sessions by subject
        subject_progress = defaultdict(list)
        for session in sessions:
            subject = session.get("subject", "unknown")
            accuracy = session["correct_answers"] / session["questions_answered"] if session["questions_answered"] > 0 else 0
            subject_progress[subject].append(accuracy)
        
        # Calculate progress for each subject
        progress_analysis = {}
        for subject, accuracies in subject_progress.items():
            progress_analysis[subject] = {
                "current_level": accuracies[-1] if accuracies else 0,
                "improvement": accuracies[-1] - accuracies[0] if len(accuracies) > 1 else 0,
                "consistency": np.std(accuracies) if len(accuracies) > 1 else 0,
                "trend": "improving" if len(accuracies) > 1 and accuracies[-1] > accuracies[0] else "stable"
            }
        
        return progress_analysis
    
    async def _calculate_engagement_metrics(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate detailed engagement metrics"""
        sessions = user_data.get("sessions", [])
        ai_interactions = user_data.get("ai_interactions", [])
        
        if not sessions:
            return {}
        
        # Time-based engagement
        session_dates = [session["date"] for session in sessions]
        unique_days = len(set(session_dates))
        
        # Interaction patterns
        help_requests = len([i for i in ai_interactions if i["interaction_type"] == "help_request"])
        
        return {
            "active_days": unique_days,
            "session_frequency": len(sessions) / max(unique_days, 1),
            "help_seeking_behavior": help_requests / len(sessions) if sessions else 0,
            "preferred_session_length": np.median([s["duration"] for s in sessions]),
            "consistency_score": self._calculate_consistency_score(session_dates)
        }
    
    def _calculate_consistency_score(self, session_dates: List[str]) -> float:
        """Calculate consistency score based on session dates"""
        if len(session_dates) < 2:
            return 0.0
        
        # Convert to datetime objects
        dates = [datetime.fromisoformat(date) for date in session_dates]
        dates.sort()
        
        # Calculate gaps between sessions
        gaps = [(dates[i+1] - dates[i]).days for i in range(len(dates)-1)]
        
        # Consistency is higher when gaps are smaller and more regular
        avg_gap = sum(gaps) / len(gaps)
        gap_variance = np.var(gaps)
        
        # Score is inversely related to gap variance
        consistency_score = max(0, 100 - gap_variance * 10)
        
        return min(consistency_score, 100)
    
    async def _analyze_skill_mastery(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze skill mastery across different topics"""
        sessions = user_data.get("sessions", [])
        assessments = user_data.get("assessments", [])
        
        # Group by subject for skill analysis
        skill_analysis = defaultdict(lambda: {"attempts": 0, "correct": 0, "mastery_level": 0})
        
        for session in sessions:
            subject = session.get("subject", "unknown")
            skill_analysis[subject]["attempts"] += session["questions_answered"]
            skill_analysis[subject]["correct"] += session["correct_answers"]
        
        # Calculate mastery levels
        for subject, data in skill_analysis.items():
            if data["attempts"] > 0:
                accuracy = data["correct"] / data["attempts"]
                # Mastery level based on accuracy and number of attempts
                mastery_level = accuracy * min(1.0, data["attempts"] / 10)
                skill_analysis[subject]["mastery_level"] = mastery_level
        
        return dict(skill_analysis)
    
    async def _generate_insights(self, user_data: Dict[str, Any], core_metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate insights and recommendations"""
        insights = []
        
        # Performance insights
        if core_metrics.get("overall_accuracy", 0) < 70:
            insights.append({
                "type": "performance",
                "severity": "warning",
                "message": "Accuracy is below 70%. Consider reviewing fundamental concepts.",
                "recommendation": "Focus on basic concepts before advancing to complex topics."
            })
        
        # Engagement insights
        if core_metrics.get("engagement_score", 0) < 50:
            insights.append({
                "type": "engagement",
                "severity": "warning",
                "message": "Low engagement detected. Consider varying study methods.",
                "recommendation": "Try different learning activities or study with peers."
            })
        
        # Learning velocity insights
        if core_metrics.get("learning_velocity", 0) < 0:
            insights.append({
                "type": "progress",
                "severity": "critical",
                "message": "Learning progress appears to be declining.",
                "recommendation": "Schedule a review session or seek additional support."
            })
        
        return insights
    
    async def generate_predictive_analytics(self, user_id: str, prediction_type: PredictionModel) -> PredictionResult:
        """Generate predictive analytics for a user"""
        try:
            # Get historical data
            historical_data = await self._get_historical_data(user_id)
            
            # Prepare features for prediction
            features = await self._prepare_prediction_features(historical_data)
            
            # Make prediction based on type
            if prediction_type == PredictionModel.SUCCESS_PROBABILITY:
                prediction = await self._predict_success_probability(features)
            elif prediction_type == PredictionModel.COMPLETION_TIME:
                prediction = await self._predict_completion_time(features)
            elif prediction_type == PredictionModel.DROPOUT_RISK:
                prediction = await self._predict_dropout_risk(features)
            elif prediction_type == PredictionModel.PERFORMANCE_FORECAST:
                prediction = await self._predict_performance_forecast(features)
            else:
                prediction = {"error": "Unknown prediction type"}
            
            return PredictionResult(
                user_id=user_id,
                model_type=prediction_type,
                prediction=prediction,
                confidence=prediction.get("confidence", 0.0),
                features_used=list(features.keys())
            )
            
        except Exception as e:
            logger.error(f"Error generating predictive analytics: {e}")
            return PredictionResult(
                user_id=user_id,
                model_type=prediction_type,
                prediction={"error": str(e)},
                confidence=0.0
            )
    
    async def _get_historical_data(self, user_id: str) -> Dict[str, Any]:
        """Get historical data for predictions"""
        # This would query comprehensive historical data
        return {
            "performance_history": [0.7, 0.75, 0.8, 0.78, 0.82],
            "engagement_history": [60, 65, 70, 68, 75],
            "session_frequency": [3, 4, 5, 4, 6],
            "time_spent": [120, 150, 180, 160, 200]
        }
    
    async def _prepare_prediction_features(self, historical_data: Dict[str, Any]) -> Dict[str, float]:
        """Prepare features for machine learning models"""
        features = {}
        
        # Performance features
        performance_history = historical_data.get("performance_history", [])
        if performance_history:
            features["avg_performance"] = np.mean(performance_history)
            features["performance_trend"] = np.polyfit(range(len(performance_history)), performance_history, 1)[0]
            features["performance_stability"] = 1 / (np.std(performance_history) + 0.01)
        
        # Engagement features
        engagement_history = historical_data.get("engagement_history", [])
        if engagement_history:
            features["avg_engagement"] = np.mean(engagement_history)
            features["engagement_trend"] = np.polyfit(range(len(engagement_history)), engagement_history, 1)[0]
        
        # Time features
        time_spent = historical_data.get("time_spent", [])
        if time_spent:
            features["avg_time_spent"] = np.mean(time_spent)
            features["time_consistency"] = 1 / (np.std(time_spent) + 0.01)
        
        return features
    
    async def _predict_success_probability(self, features: Dict[str, float]) -> Dict[str, Any]:
        """Predict success probability"""
        # Simple heuristic model (would be replaced with trained ML model)
        avg_performance = features.get("avg_performance", 0.5)
        avg_engagement = features.get("avg_engagement", 50)
        performance_trend = features.get("performance_trend", 0)
        
        # Combine factors
        success_probability = (
            avg_performance * 0.5 +
            (avg_engagement / 100) * 0.3 +
            max(0, performance_trend) * 0.2
        )
        
        return {
            "success_probability": min(success_probability, 1.0),
            "confidence": 0.75,
            "factors": {
                "performance_contribution": avg_performance * 0.5,
                "engagement_contribution": (avg_engagement / 100) * 0.3,
                "trend_contribution": max(0, performance_trend) * 0.2
            }
        }
    
    async def _predict_completion_time(self, features: Dict[str, float]) -> Dict[str, Any]:
        """Predict completion time for learning objectives"""
        avg_time = features.get("avg_time_spent", 120)
        performance_level = features.get("avg_performance", 0.5)
        
        # Adjust time based on performance
        efficiency_factor = performance_level * 2  # Higher performance = faster completion
        predicted_time = avg_time / max(efficiency_factor, 0.5)
        
        return {
            "predicted_completion_time": predicted_time,
            "confidence": 0.65,
            "time_unit": "minutes",
            "factors": {
                "base_time": avg_time,
                "efficiency_factor": efficiency_factor
            }
        }
    
    async def _predict_dropout_risk(self, features: Dict[str, float]) -> Dict[str, Any]:
        """Predict dropout risk"""
        engagement_trend = features.get("engagement_trend", 0)
        avg_engagement = features.get("avg_engagement", 50)
        performance_trend = features.get("performance_trend", 0)
        
        # Risk factors
        risk_factors = []
        risk_score = 0
        
        if engagement_trend < -2:
            risk_factors.append("Declining engagement")
            risk_score += 0.3
        
        if avg_engagement < 30:
            risk_factors.append("Low overall engagement")
            risk_score += 0.4
        
        if performance_trend < -0.05:
            risk_factors.append("Declining performance")
            risk_score += 0.3
        
        return {
            "dropout_risk": min(risk_score, 1.0),
            "risk_level": "high" if risk_score > 0.7 else "medium" if risk_score > 0.3 else "low",
            "risk_factors": risk_factors,
            "confidence": 0.70
        }
    
    async def _predict_performance_forecast(self, features: Dict[str, float]) -> Dict[str, Any]:
        """Predict future performance"""
        current_performance = features.get("avg_performance", 0.5)
        performance_trend = features.get("performance_trend", 0)
        
        # Forecast next 4 weeks
        forecast = []
        for week in range(1, 5):
            predicted = current_performance + (performance_trend * week)
            predicted = max(0, min(1, predicted))  # Clamp between 0 and 1
            forecast.append({
                "week": week,
                "predicted_performance": predicted
            })
        
        return {
            "performance_forecast": forecast,
            "trend_direction": "improving" if performance_trend > 0 else "declining" if performance_trend < 0 else "stable",
            "confidence": 0.60
        }
    
    async def generate_report(self, report_type: ReportType, target_id: str, generated_by: str) -> Report:
        """Generate comprehensive report"""
        try:
            report_data = {}
            
            if report_type == ReportType.INDIVIDUAL_STUDENT:
                report_data = await self._generate_individual_student_report(target_id)
            elif report_type == ReportType.CLASS_SUMMARY:
                report_data = await self._generate_class_summary_report(target_id)
            elif report_type == ReportType.SUBJECT_PERFORMANCE:
                report_data = await self._generate_subject_performance_report(target_id)
            elif report_type == ReportType.ENGAGEMENT_REPORT:
                report_data = await self._generate_engagement_report(target_id)
            elif report_type == ReportType.PREDICTIVE_REPORT:
                report_data = await self._generate_predictive_report(target_id)
            
            return Report(
                report_type=report_type,
                title=f"{report_type.value.replace('_', ' ').title()} Report",
                description=f"Comprehensive {report_type.value} analysis",
                generated_for=target_id,
                data=report_data,
                generated_by=generated_by
            )
            
        except Exception as e:
            logger.error(f"Error generating report: {e}")
            return Report(
                report_type=report_type,
                title="Error Report",
                description=f"Error generating report: {str(e)}",
                generated_for=target_id,
                data={"error": str(e)},
                generated_by=generated_by
            )
    
    async def _generate_individual_student_report(self, user_id: str) -> Dict[str, Any]:
        """Generate individual student report"""
        # Get comprehensive analytics
        analytics = await self.generate_learning_analytics(user_id)
        
        # Get predictions
        success_prediction = await self.generate_predictive_analytics(user_id, PredictionModel.SUCCESS_PROBABILITY)
        
        return {
            "student_overview": {
                "user_id": user_id,
                "report_period": "Last 30 days",
                "generated_at": datetime.now(timezone.utc).isoformat()
            },
            "performance_summary": analytics.get("core_metrics", {}),
            "learning_progress": analytics.get("learning_progress", {}),
            "engagement_analysis": analytics.get("engagement_metrics", {}),
            "skill_mastery": analytics.get("skill_analysis", {}),
            "predictions": success_prediction.prediction,
            "recommendations": analytics.get("insights", [])
        }
    
    async def _generate_class_summary_report(self, class_id: str) -> Dict[str, Any]:
        """Generate class summary report"""
        # This would aggregate data for all students in a class
        return {
            "class_overview": {
                "class_id": class_id,
                "total_students": 25,
                "active_students": 22,
                "report_period": "Last 30 days"
            },
            "performance_distribution": {
                "excellent": 8,
                "good": 10,
                "average": 6,
                "needs_improvement": 1
            },
            "engagement_metrics": {
                "avg_session_time": 45,
                "avg_sessions_per_week": 3.5,
                "help_requests": 150
            },
            "skill_gaps": [
                {"topic": "Algebra", "students_struggling": 5},
                {"topic": "Geometry", "students_struggling": 3}
            ]
        }
    
    async def _generate_subject_performance_report(self, subject: str) -> Dict[str, Any]:
        """Generate subject performance report"""
        return {
            "subject_overview": {
                "subject": subject,
                "total_students": 100,
                "avg_performance": 78.5
            },
            "topic_analysis": {
                "strongest_topics": ["Basic Arithmetic", "Fractions"],
                "weakest_topics": ["Algebra", "Word Problems"]
            },
            "difficulty_trends": {
                "easy_questions": {"avg_score": 85, "completion_rate": 95},
                "medium_questions": {"avg_score": 75, "completion_rate": 88},
                "hard_questions": {"avg_score": 65, "completion_rate": 72}
            }
        }
    
    async def _generate_engagement_report(self, target_id: str) -> Dict[str, Any]:
        """Generate engagement report"""
        return {
            "engagement_overview": {
                "target_id": target_id,
                "overall_engagement": 75,
                "trend": "improving"
            },
            "activity_patterns": {
                "peak_hours": ["3:00 PM", "7:00 PM"],
                "peak_days": ["Monday", "Wednesday", "Friday"],
                "avg_session_length": 42
            },
            "interaction_analysis": {
                "ai_help_usage": 65,
                "peer_collaboration": 35,
                "self_directed_learning": 80
            }
        }
    
    async def _generate_predictive_report(self, target_id: str) -> Dict[str, Any]:
        """Generate predictive analytics report"""
        # Get multiple predictions
        success_pred = await self.generate_predictive_analytics(target_id, PredictionModel.SUCCESS_PROBABILITY)
        dropout_pred = await self.generate_predictive_analytics(target_id, PredictionModel.DROPOUT_RISK)
        performance_pred = await self.generate_predictive_analytics(target_id, PredictionModel.PERFORMANCE_FORECAST)
        
        return {
            "predictive_overview": {
                "target_id": target_id,
                "prediction_date": datetime.now(timezone.utc).isoformat()
            },
            "success_probability": success_pred.prediction,
            "dropout_risk": dropout_pred.prediction,
            "performance_forecast": performance_pred.prediction,
            "intervention_recommendations": [
                "Increase engagement through gamification",
                "Provide additional support in weak areas",
                "Encourage peer collaboration"
            ]
        }

# Global instance
analytics_engine = AdvancedAnalyticsEngine()